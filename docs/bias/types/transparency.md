---
title: "Transparency"
type: ["opacity"]
stages: ["setup", "collection", "process", "share"]
keywords: ["reuse", "documentation", "contextualisation", "audit"]
---



## Definition
"make data, analysis, methods, and interpretive choices underlying their claims visible in a way that allows others to evaluate them"

_Definition source: **Princeton (n.d.). [Transparency in Qualitative Research](https://www.princeton.edu/~amoravcs/library/TransparencyinQualitativeResearch.pdf).**_

## Stakes
_part of: **opacity**_

Transparency is crucial in research: in documentation, communication, publications. Research that lacks transparency causes wrongful reiterations and conclusions to be drawn - it also does not encourage responsible reuse of knowledge.

## Where does it occur in the lifecycle?

**1 - Set up**

- Write Ethical Commitments
- Write Mission Statement

**2 - Collection**
- Create metadata for the data
- Reflect: Revisit your Set Up documentation

**3 - Process**
- Annotate your data

**5 - Share & Preserve**
- Contextualise data for external users


## Questions to consider throughout your work
- Do you have any ethical concerns about the research? Think of: harm that can be done, accessibility issues, etc.
- How active will your intervention be?
- Who will your research impact positively/negatively?
- What is the proposed outcome of the research? Could there be unintended uses and/or consequences?
- What values drive your work and how are they reflected in your work? 
- What are you basing your metadata descriptions on?
- What are you basing your annotations on?
- If you identified gaps during analysis process: how are you representing these to your audience? 
    - For example, visualisations documentation, etc.
- What alternative resources that may address gaps/relevant topics to your research do you refer your users to?
    - Have/Can you link this data to other archives/data?

## Examples
- 

## Good-better-best practices

| Good | Better | Best|
|---|---|---|
|Store older versions of documentation to reflect and build on, and for internal (and external) audit.| Make public all documentation on project process, creation of documentation. This is for a public audit of your project as a whole.| “Make sure institution-created description is assessed by outside communities.”[^1]|
| Provide a feedback mechanism such as creating a highly visible “Suggest a Correction” button or comment form on online finding aids, and make it clear that you welcome this kind of feedback.| Create awareness in your publications of the impact your research (both positive and negative) may have, that you may be aware of.[^2]| “Increase the transparency of data access conditions” and use so that users know exactly whether and how they can use your data once it is published.[^3]|
|Be open about information on project funding, project team and their tasks, data licenses (in case of reuse), research timeline, and sources used. Also outline selection criteria (of data) and their annotation criteria. | | Maintain dataset versioning and ensure that the documentation plots the different changes made in the different versions of data and metadata. | 

## Resources
-

[^1]: Taken from Archives for Black Lives, <a href='https://archivesforblacklives.wordpress.com/wp-content/uploads/2019/10/ardr_final.pdf'>Anti-Racist Description Resources</a> (2019), p. 6.
[^2]: Adapted from DE-BIAS, [A Community Engagement Methodology: resources, reflections, recommendations](https://pro.europeana.eu/files/Europeana_Professional/Projects/debias/a_community_engagement_methodology_resources_reflections_recommendations_v3_july_2024.pdf) (2024).
[^3]: Deborah Thorpe, Ricarda Braukman and Angelica Maineri, “Improving the Transparency of Data Access Conditions in the SSH Domain: Recommendations based on a small-scale analysis of the conditions applied to restricted access datasets,” _International Journal of Digital Curation_, Vol. 19, No. 1 (2025). https://ijdc.net/index.php/ijdc/article/view/1048  