---
title: "Historicity"
type: ["discrimination", "opacity"]
stages: ["collection"]
keywords: ["original", "primary source", "significance", "context"]
---

## Definition
Philosophical term denoting an authenticity of an event in the past. 

_Definition source: **Combatting Bias definition**._

## Stakes
_part of: **opacity, discrimination**_

_related to: **harmful language**_

Historicity is important because we do not want to erase past wrongs. A dataset or narrative for historical research must include flaws, but must also be contextualised and not reiterated responsibly. 

## Where does it occur in the lifecycle?

**2 - Collection**

- [Select and curate sources and/or data](/lifecycle/collection/#select-and-curate-sources-andor-data)
- [Create usable categories and variables for your dataset](/lifecycle/collection/#create-usable-categories-and-variables-for-your-dataset)


## Questions to consider throughout your work
- Did you modify the data from its original source? 
- Are you using terms as they are in the source document (extraction/verbatim)? Or did you interpret content in the source document in order to capture the data point? 
    - e.g. Sex of a person can be explicitly stated in the document or interpreted by the data collector (through names, for example). 
- Are you using categories as used by your sources? If so, consider elaborating your choice of categories to your users. 

## Examples
- Use of Alt- (or Hidden) and PrefLabels in datasets: Vellinga, Henrike; Pham, Thuy Dung; Brink, Femke; Pepping, Kay; Kuruppath, Manjusha, 2025, "GLOBALISE - Ethnicities, Religious Groups and Castes in the Archives of the Dutch East India Company (1602-1799)", https://hdl.handle.net/10622/5LRS03, IISH Data Collection, V1, UNF:6:siBQYpYn3SrbefB1bA6wLQ== [fileUNF].
    - You might want to identify a PrefLabel that is not problematic and relegate a problematic label to be an AltLabel or a Hidden Label.

## Good-better-best practices

| Good | Better | Best |
|---|---|---|
| Ensure primary documents and descriptions are not erased. Contextualise potentially harmful descriptions and words and problematise them.|Curate your dataset mindful of how it will be viewed, read and used.[^1]|Ensure that your dataset is able to demonstrate the difference between original source content and dataset creator’s intervention. Where this difference has been glossed over or erased, indicate to the user.|

## Resources
- Bode, Katherine. “Why You Can’t Model Away Bias.” Modern Language Quarterly 81, no. 1 (2020): 95–124. https://doi.org/10.1215/00267929-7933102.


[^1]: For example, you might want to identify a PrefLabel that is not problematic and relegate a problematic label to be an AltLabel or a Hidden Label. Vellinga, Henrike; Pham, Thuy Dung; Brink, Femke; Pepping, Kay; Kuruppath, Manjusha, 2025, "GLOBALISE - Ethnicities, Religious Groups and Castes in the Archives of the Dutch East India Company (1602-1799)", https://hdl.handle.net/10622/5LRS03, IISH Data Collection, V1, UNF:6:siBQYpYn3SrbefB1bA6wLQ== [fileUNF]